{
    "name": "root",
    "gauges": {
        "Pou.Policy.Entropy.mean": {
            "value": 0.632732629776001,
            "min": 0.6215865015983582,
            "max": 0.6813081502914429,
            "count": 10
        },
        "Pou.Policy.Entropy.sum": {
            "value": 31646.123046875,
            "min": 31113.51171875,
            "max": 34069.49609375,
            "count": 10
        },
        "Pou.Step.mean": {
            "value": 499977.0,
            "min": 49993.0,
            "max": 499977.0,
            "count": 10
        },
        "Pou.Step.sum": {
            "value": 499977.0,
            "min": 49993.0,
            "max": 499977.0,
            "count": 10
        },
        "Pou.Policy.ExtrinsicValueEstimate.mean": {
            "value": -0.46294671297073364,
            "min": -0.7544286251068115,
            "max": 0.4544699788093567,
            "count": 10
        },
        "Pou.Policy.ExtrinsicValueEstimate.sum": {
            "value": -446.2806396484375,
            "min": -702.62939453125,
            "max": 422.2026062011719,
            "count": 10
        },
        "Pou.Environment.EpisodeLength.mean": {
            "value": 162.7672131147541,
            "min": 160.2332268370607,
            "max": 195.84375,
            "count": 10
        },
        "Pou.Environment.EpisodeLength.sum": {
            "value": 49644.0,
            "min": 49333.0,
            "max": 50153.0,
            "count": 10
        },
        "Pou.Environment.CumulativeReward.mean": {
            "value": -0.4300653563897594,
            "min": -4.05401459496713,
            "max": -0.4300653563897594,
            "count": 10
        },
        "Pou.Environment.CumulativeReward.sum": {
            "value": -131.59999905526638,
            "min": -1110.7999990209937,
            "max": -131.59999905526638,
            "count": 10
        },
        "Pou.Policy.ExtrinsicReward.mean": {
            "value": -0.4300653563897594,
            "min": -4.05401459496713,
            "max": -0.4300653563897594,
            "count": 10
        },
        "Pou.Policy.ExtrinsicReward.sum": {
            "value": -131.59999905526638,
            "min": -1110.7999990209937,
            "max": -131.59999905526638,
            "count": 10
        },
        "Pou.Losses.PolicyLoss.mean": {
            "value": 0.025072646220214663,
            "min": 0.021623595627024768,
            "max": 0.028076516299818954,
            "count": 10
        },
        "Pou.Losses.PolicyLoss.sum": {
            "value": 0.1253632311010733,
            "min": 0.09858812869448835,
            "max": 0.14038258149909477,
            "count": 10
        },
        "Pou.Losses.ValueLoss.mean": {
            "value": 0.2870900831123193,
            "min": 0.2870900831123193,
            "max": 2.214523525039355,
            "count": 10
        },
        "Pou.Losses.ValueLoss.sum": {
            "value": 1.4354504155615966,
            "min": 1.4354504155615966,
            "max": 8.85809410015742,
            "count": 10
        },
        "Pou.Policy.LearningRate.mean": {
            "value": 1.6360894546400004e-05,
            "min": 1.6360894546400004e-05,
            "max": 0.00028459365513545,
            "count": 10
        },
        "Pou.Policy.LearningRate.sum": {
            "value": 8.180447273200002e-05,
            "min": 8.180447273200002e-05,
            "max": 0.0012838146720617997,
            "count": 10
        },
        "Pou.Policy.Epsilon.mean": {
            "value": 0.1054536,
            "min": 0.1054536,
            "max": 0.19486455000000003,
            "count": 10
        },
        "Pou.Policy.Epsilon.sum": {
            "value": 0.527268,
            "min": 0.49985640000000003,
            "max": 0.9279382000000002,
            "count": 10
        },
        "Pou.Policy.Beta.mean": {
            "value": 0.00028213464000000006,
            "min": 0.00028213464000000006,
            "max": 0.0047437410449999995,
            "count": 10
        },
        "Pou.Policy.Beta.sum": {
            "value": 0.0014106732000000004,
            "min": 0.0014106732000000004,
            "max": 0.02140411618,
            "count": 10
        },
        "Pou.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        },
        "Pou.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 10
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1677158860",
        "python_version": "3.9.2rc1 (tags/v3.9.2rc1:4064156, Feb 17 2021, 11:25:18) [MSC v.1928 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\david\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\mlagents-learn --run-id=Pou06",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1677159500"
    },
    "total": 640.3453926,
    "count": 1,
    "self": 0.013505699999996068,
    "children": {
        "run_training.setup": {
            "total": 0.045370800000000155,
            "count": 1,
            "self": 0.045370800000000155
        },
        "TrainerController.start_learning": {
            "total": 640.2865161,
            "count": 1,
            "self": 2.1706965000055334,
            "children": {
                "TrainerController._reset_env": {
                    "total": 6.202210599999999,
                    "count": 1,
                    "self": 6.202210599999999
                },
                "TrainerController.advance": {
                    "total": 631.8415867999945,
                    "count": 79802,
                    "self": 1.891829000000257,
                    "children": {
                        "env_step": {
                            "total": 457.73119400000303,
                            "count": 79802,
                            "self": 350.58652140000623,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 105.79409969999705,
                                    "count": 79802,
                                    "self": 5.50643060000111,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 100.28766909999594,
                                            "count": 79802,
                                            "self": 100.28766909999594
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.3505728999997668,
                                    "count": 79802,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 631.4042479000074,
                                            "count": 79802,
                                            "is_parallel": true,
                                            "self": 387.2712045000118,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.0004888999999996813,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00025340000000007024,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.00023549999999961102,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.00023549999999961102
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 244.1325544999956,
                                                    "count": 79802,
                                                    "is_parallel": true,
                                                    "self": 9.57134500000609,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 14.018583399994572,
                                                            "count": 79802,
                                                            "is_parallel": true,
                                                            "self": 14.018583399994572
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 191.88568869999528,
                                                            "count": 79802,
                                                            "is_parallel": true,
                                                            "self": 191.88568869999528
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 28.65693739999962,
                                                            "count": 79802,
                                                            "is_parallel": true,
                                                            "self": 15.881127199993417,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 12.775810200006203,
                                                                    "count": 159604,
                                                                    "is_parallel": true,
                                                                    "self": 12.775810200006203
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 172.21856379999124,
                            "count": 79802,
                            "self": 2.761342499984096,
                            "children": {
                                "process_trajectory": {
                                    "total": 46.31694070000708,
                                    "count": 79802,
                                    "self": 46.21273790000703,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.10420280000005278,
                                            "count": 1,
                                            "self": 0.10420280000005278
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 123.14028060000007,
                                    "count": 48,
                                    "self": 84.75319040000073,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 38.387090199999335,
                                            "count": 1440,
                                            "self": 38.387090199999335
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 9.999999974752427e-07,
                    "count": 1,
                    "self": 9.999999974752427e-07
                },
                "TrainerController._save_models": {
                    "total": 0.07202119999999468,
                    "count": 1,
                    "self": 0.01268819999995685,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.05933300000003783,
                            "count": 1,
                            "self": 0.05933300000003783
                        }
                    }
                }
            }
        }
    }
}